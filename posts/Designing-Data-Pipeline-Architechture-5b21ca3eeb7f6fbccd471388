{
	"_id ": "5b21ca3eeb7f6fbccd471388",
	"id": "Designing-Data-Pipeline-Architechture-5b21ca3eeb7f6fbccd471388",
	"title": "Designing Data Pipeline Architechture",
	"topic": {
		"_id": "5b21ca3eeb7f6fbccd486891",
		"name": "Data Analytics"
	},
	"numberInStock": 6,
	"dailyRentalRate": 2.5,
	"publishDate": "2021-06-16T19:04:28.809Z",
	"metadata": ["Data Pipeline Architecture is an intrinsic part of software engineering. With everyday increase in data, companies are finding innovative ways for data mining. Every type of data is important from user data to server logs. Data analytics provides insights about the behaviour of systems. With increase in data consumption data too has increased. Machine learning and AI are data hungry. No data is more for these models. But the data is not always structured that could be readily consumed. The huge amount of time and resources goes into cleaning. Every unstructured data needs to be processed and stored properly. Many systems are involved in this process. Different types of data require different types of processing and storage. That is why designing data pipeline architecture is different in different companies, different projects or different data types."],
	"content": {
		"rows": 7,
		"coumns": 0,
		"images": {},
		"text": [{
				"row": 0,
				"column": 0,
				"type": "heading",
				"value": ["Basic components of Data Pipeline"]
			},
			{
				"row": 1,
				"column": 0,
				"type": "paragraph",
				"value": ["Every data pipeline requires at least four components, Data source, Processing Systems, Data Storage and Query engine."]
			},
			{
				"row": 2,
				"column": 0,
				"type": "image",
				"caption": ["Data Pipeline Architecture"],
				"reference":"images/data_pipeline_arch.jpg"
			},
			{
				"row": 3,
				"column": 0,
				"type": "subheading",
				"value": ["Data Source"]
			},
			{
				"row": 4,
				"column": 0,
				"type": "paragraph",
				"value": ["There could be one or many data sources for the data pipeline. Ideally, data sources are transactional databases like Mysql, Postgres, or NoSQL like MongoDB. In some cases, if data is media files like photos, documents source could be S3 or any other object-store. There could be real-time sources too like stream data from mobiles, logs from servers or databases(Change Data Capture). If the data source is streamed probably message queue is required. Message queue acts as a buffer for the processing unit. Popular message queues like Kafka and rabbitMQ can be used."]
			},
			{
				"row": 5,
				"column": 0,
				"type": "heading",
				"value": ["How to use bloom filters"]
			},
			{
				"row": 6,
				"column": 0,
				"type": "paragraph",
				"value": [""]
			},
			{
				"row": 7,
				"column": 0,
				"type": "heading",
				"value": ["Where is bloom filters used"]
			},
			{
				"row": 8,
				"column": 0,
				"type": "paragraph",
				"value": [""]
			},
			{
				"row": 9,
				"column": 0,
				"type": "heading",
				"value": [""]
			},
			{
				"row": 10,
				"column": 0,
				"type": "paragraph",
				"value": [""]
			},
			{
				"row": 11,
				"column": 0,
				"type": "heading",
				"value": ["When using source or target or combined data"]
			},
			{
				"row": 12,
				"column": 0,
				"type": "paragraph",
				"value": [""]
			},
			{
				"row": 13,
				"column": 0,
				"type": "paragraph",
				"value": [""]
			},
			{
				"row": 14,
				"column": 0,
				"type": "heading",
				"value": ["References"]
			},
			{
				"row": 15,
				"column": 0,
				"type": "references",
				"value": [{
					"authors": "Xingyi Yang∗, Xuehai He∗,Yuxiao Liang, Yue Yang",
					"title": "Transfer Learning or Self-supervised Learning? A Tale of Two Pretraining Paradigms"
				}]
			}
		]
	}
}
